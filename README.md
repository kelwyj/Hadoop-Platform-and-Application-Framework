# Hadoop-Platform-and-Application-Framework


Course Website
This class is 1 of 6 offered by UC San Diego for their Big Data Specialization certificate on Coursera. 
The course covers Hadoop architecture, software stack, and execution environment, walking through hands-on examples of the Hadoop and Spark frameworks.
This course is for novice programmers or business people who would like to understand the core tools used to wrangle and analyze big data. With no prior experience, you will have the opportunity to walk through hands-on examples with Hadoop and Spark frameworks, two of the most common in the industry. You will be comfortable explaining the specific components and basic processes of the Hadoop architecture, software stack, and execution environment.   In the assignments you will be guided in how data scientists apply the important concepts and techniques such as Map-Reduce that are used to solve fundamental problems in big data.  You'll feel empowered to have conversations about big data and the data analysis process.

In Week 4 of the course, this module will introduce Map/Reduce concepts and practice. we will learn the big idea of Map/Reduce and we learn how to design, implement, and execute tasks in the map/reduce framework. we also learn the trade-offs in map/reduce and how that motivates other tools.we discuss the Map/Reduce framework with two exercises in Hadoop streaming using Python:

Wordcount
Joining Data
Join 1
Join 2

Welcome to module 5, Introduction to Spark, this week we will focus on the Apache Spark cluster computing framework, an important contender of Hadoop MapReduce in the Big Data Arena. Spark provides great performance advantages over Hadoop MapReduce,especially for iterative algorithms, thanks to in-memory caching. Also, gives Data Scientists an easier way to write their analysis pipeline in Python and Scala,even providing interactive shells to play live with data.

Week 5 covers the Spark framework with two join exercises using spark.

Simple Join
Advanced Join
